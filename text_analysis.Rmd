---
title: "Analyzing sentiments"
author: "Tero Jalkanen"
date: "`r Sys.Date()`"
output: ioslides_presentation
params:
  filter_duplicates: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)

## Packages -----------

library(readxl)
library(here)
library(tidyverse)
library(janitor)
library(skimr)
library(tidytext)
library(scales)

## Set file paths
here::i_am("text_analysis.Rmd")

## Set graphical theme
theme_set(theme_minimal())

```

## Data 

* The data contains 266 sentences which have been assessed as being `positive`, `negative` or `neutral`.

* We want to explore the data and see if it is useful for sentiment analysis.

## General properties of the data

* There are no missing entries

```{r}

text_df <- readxl::read_excel(path = here("data", "sentences_with_sentiment.xlsx")) %>% 
  # move sentiments under same column
  mutate(sentiment = case_when(
    Positive == 1 ~ "Positive",
    Negative == 1 ~ "Negative",
    Neutral == 1 ~ "Neutral",
    # in case of missing sentiment
    TRUE ~ "missing"
  ), .after = ID) %>% 
  janitor::clean_names()

# Let's take a look at the data
skim(text_df)

```

## The balance of sentiments


```{r}

text_df %>% 
  group_by(sentiment) %>% 
  summarise(n = n()) %>% 
  mutate(prercentage = 100*n/length(text_df$sentiment)) %>% 
  knitr::kable(digits = 2, caption = "The sentiment labels for the example sentences")

```

## Unique sentences

Check if there are duplicate sentences.

```{r}
## Find duplicate sentences ----

# indices
double_ind <- duplicated(text_df$sentence)

# The actual sentences
doubles <- text_df$sentence[double_ind] %>% 
  unique()

```

* There are `r length(doubles)` sentences which appear at least twice.

```{r}

# Let's print out the first example
text_df %>% 
  filter(sentence %in% doubles[1]) %>% 
  select(sentiment, sentence)


```

## Duplicated sentences with differing sentiment label

Are there duplicated sentences, where the sentence has been labelled differently?

```{r}

doubles_df <- data.frame(sentence = doubles, double_id = 1:length(doubles))

text_df %>% 
  filter(sentence %in% doubles) %>% 
  left_join(doubles_df, by = "sentence") %>% 
  group_by(double_id, sentiment) %>% 
  summarise(n = n())

```

## What happens to sentiment balance without duplicates?

```{r}
# sentiments without duplicates
no_doubles_df <- text_df %>%
  select(-id) %>% 
  # include doubles only once
  unique.data.frame()


#balance table
no_doubles_df %>% 
  group_by(sentiment) %>% 
  summarise(n = n()) %>% 
  mutate(prercentage = 100*n/length(no_doubles_df$sentiment)) %>% 
  knitr::kable(digits = 2, caption = "The sentiment labels for the example sentences")


## Filter out duplicate sentences if the filtering parameter is set to TRUE
if(params$filter_duplicates){
  # remove duplicate entiries
  # each sentence only appears once
  text_df <- text_df[!double_ind,]
}


```


## Things to consider

* Should we use the duplicated sentences only once?

  - Having the same sentence with the same sentiment label twice does not add new information

  - Added a parameter to filter out duplicate sentences

* How to deal with the imbalance between sentiments?

* Evaluating classification performance?

# Extracting words as tokens

## Extracting words as tokens

* Use words, as tokens, everything in small letters, remove punctuation, stopwords etc.

```{r}
# The first sentence in the data
print(text_df$sentence[1])

# A tidy version with words as tokens
(tidy_df <- text_df %>% 
  unnest_tokens(word, sentence))

```

## Removing stopwords

```{r}

data("stop_words")

(tidy_df <- tidy_df %>% 
  anti_join(stop_words))

```

## Most common words

```{r}
tidy_df %>% 
  count(word, sort = TRUE) %>% 
  head(15) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(x = n, y = word)) +
  geom_col() +
  labs(y = NULL) +
  ggtitle("Most common words in the example sentences",
          subtitle = "Excluding common stopwords")
```


## Which words associate with different sentiments

```{r}

tidy_df %>% 
  count(sentiment, word) %>% 
  group_by(sentiment) %>% 
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  pivot_wider(names_from = sentiment, values_from = proportion) %>% 
  pivot_longer(Negative:Neutral, names_to = "sentiment", values_to = "proportion") %>% 
  ggplot(aes(x = proportion, y = Positive, color = abs(Positive - proportion))) +
  geom_abline(lty = 2) +
  geom_point(size = 2.5, alpha = 0.5) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "darkslategray4", high = "gray75") +
  facet_grid(sentiment ~ .) +
  labs(x = NULL) +
  theme(legend.position = "none")
  
  

```

## Slide with Plot

```{r pressure}
plot(pressure)
```

