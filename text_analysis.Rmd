---
title: "Analyzing sentiments"
author: "Tero Jalkanen"
date: "`r Sys.Date()`"
output: ioslides_presentation
params:
  filter_duplicates: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)

## Packages -----------

library(readxl)
library(here)
library(tidyverse)
library(janitor)
library(skimr)
library(tidytext)
library(scales)
library(textdata)
library(RColorBrewer)
library(wordcloud)
library(reshape2)

## Set file paths
here::i_am("text_analysis.Rmd")

## Set graphical theme
theme_set(theme_minimal())

```

## Data 

* The data contains 266 sentences which have been assessed as being `positive`, `negative` or `neutral`.

* We want to explore the data and see if it is useful for sentiment analysis.

## General properties of the data

* There are no missing entries

```{r}

text_df <- readxl::read_excel(path = here("data", "sentences_with_sentiment.xlsx")) %>% 
  # move sentiments under same column
  mutate(sentiment = case_when(
    Positive == 1 ~ "Positive",
    Negative == 1 ~ "Negative",
    Neutral == 1 ~ "Neutral",
    # in case of missing sentiment
    TRUE ~ "missing"
  ), .after = ID) %>% 
  janitor::clean_names()

# Let's take a look at the data
skim(text_df)

```

## The balance of sentiments


```{r}

text_df %>% 
  group_by(sentiment) %>% 
  summarise(n = n()) %>% 
  mutate(prercentage = 100*n/length(text_df$sentiment)) %>% 
  knitr::kable(digits = 2, caption = "The sentiment labels for the example sentences")

```

## Unique sentences

Check if there are duplicate sentences.

```{r}
## Find duplicate sentences ----

# indices
double_ind <- duplicated(text_df$sentence)

# The actual sentences
doubles <- text_df$sentence[double_ind] %>% 
  unique()

```

* There are `r length(doubles)` sentences which appear at least twice.

```{r}

# Let's print out the first example
text_df %>% 
  filter(sentence %in% doubles[1]) %>% 
  select(sentiment, sentence)


```

## Duplicated sentences with differing sentiment label

Are there duplicated sentences, where the sentence has been labelled differently?

```{r}

doubles_df <- data.frame(sentence = doubles, double_id = 1:length(doubles))

text_df %>% 
  filter(sentence %in% doubles) %>% 
  left_join(doubles_df, by = "sentence") %>% 
  group_by(double_id, sentiment) %>% 
  summarise(n = n())

```

## What happens to sentiment balance without duplicates?

```{r}
# sentiments without duplicates
no_doubles_df <- text_df %>%
  select(-id) %>% 
  # include doubles only once
  unique.data.frame()


#balance table
no_doubles_df %>% 
  group_by(sentiment) %>% 
  summarise(n = n()) %>% 
  mutate(prercentage = 100*n/length(no_doubles_df$sentiment)) %>% 
  knitr::kable(digits = 2, caption = "The sentiment labels for the example sentences")


## Filter out duplicate sentences if the filtering parameter is set to TRUE
if(params$filter_duplicates){
  # remove duplicate entiries
  # each sentence only appears once
  text_df <- text_df[!double_ind,]
}


```


## Things to consider

* Should we use the duplicated sentences only once?

  - Having the same sentence with the same sentiment label twice does not add new information

  - Added a parameter to filter out duplicate sentences

* How to deal with the imbalance between sentiments?

* Evaluating classification performance?

# Extracting words as tokens

## Extracting words as tokens

* Use words, as tokens, everything in small letters, remove punctuation, stopwords etc.

```{r}
# The first sentence in the data
print(text_df$sentence[1])

# A tidy version with words as tokens
(tidy_df <- text_df %>% 
  unnest_tokens(word, sentence))

```

## Removing stopwords

```{r}

data("stop_words")

(tidy_df <- tidy_df %>% 
  anti_join(stop_words))

```

## Most common words

```{r}
tidy_df %>% 
  count(word, sort = TRUE) %>% 
  head(15) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(x = n, y = word)) +
  geom_col() +
  labs(y = NULL) +
  ggtitle("Most common words in the example sentences",
          subtitle = "Excluding common stopwords")
```


## Which words associate with different sentiments

```{r, warning=FALSE}

tidy_df %>% 
  count(sentiment, word) %>% 
  group_by(sentiment) %>% 
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  pivot_wider(names_from = sentiment, values_from = proportion) %>% 
  pivot_longer(Negative:Neutral, names_to = "sentiment", values_to = "proportion") %>% 
  ggplot(aes(x = proportion, y = Positive, color = abs(Positive - proportion))) +
  geom_abline(lty = 2) +
  geom_point(size = 2.5, alpha = 0.5) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "darkslategray4", high = "gray75") +
  facet_grid(sentiment ~ .) +
  labs(x = "Negative (up) / Neutral (down)") +
  theme(legend.position = "none")
  
  

```

## Positive/Negative words

```{r}

tidy_df %>% 
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)

```



# Attaching sentiments to individual words

## Sentiments from dictionaries

* A number of readily available sentiment dictionaries are available, which help us attach emotion to single words

> Dictionary-based methods find the total sentiment of a piece of text by adding up the individual sentiment scores for each word in the text.

* Example ([AFINN](http://www2.imm.dtu.dk/pubdb/pubs/6010-full.html) dictionary by Finn Årup Nielsen):

```{r}

get_sentiments("afinn") %>% 
  head(3)

```

## Attach sentiment to sentences

```{r}

tidy_df %>% 
  # Add sentiment scores for words from afinn dictionary 
  inner_join(get_sentiments("afinn")) %>% 
  count(id, sentiment, value) %>% 
  group_by(id, sentiment) %>% 
  summarise(sentiment_score = sum(value*n)) %>% 
  # Re-order sentiments for the plot
  mutate(sentiment = factor(sentiment, levels = c("Positive", "Neutral", "Negative"))) %>% 
  ggplot(aes(x = id, y = sentiment_score, fill = sentiment)) +
  geom_col() +
  ggtitle("Sentiments from AFINN dictionary by Finn Årup Nielsen") +
  scale_fill_manual(values = brewer.pal(n = 3, name = "Set2")) +
  labs(y = "Sentiment scores for sentences", x = "Sentence ID")

```

* Drawbacks such as many words are missing from this dictionary

# n-grams instead of words



