[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning to Fly",
    "section": "",
    "text": "Preface\nThis document is a tool to help me write down some key concepts that I come across as I’m learning to analyze data in text format. I want to document my learning experience and take some notes that I can re-visit if needed."
  },
  {
    "objectID": "intro.html#some-basic-concepts-related-to-handling-text",
    "href": "intro.html#some-basic-concepts-related-to-handling-text",
    "title": "1  Introduction",
    "section": "1.1 Some basic concepts related to handling text",
    "text": "1.1 Some basic concepts related to handling text\n\nString: a data type consisting of a sequence of characters\nToken: a meaningful unit of text such as a word, sentence, lines of text, paragraphs etc.\nCorpus: In linguistics, a corpus (plural corpora) or text corpus is a language resource consisting of a large and structured set of texts (nowadays usually electronically stored and processed). In NLP context, corpus usually stores the text along with metadata.\nDocument-term matrix: a matrix where each row presents one document (such as a book or article), each column represents one term, and each value states the number of appearances in of that term in the document (Silge and Robinson 2017)\nn-gram: An n-gram (sometimes written “ngram”) is a term in linguistics for a contiguous sequence of \\(n\\) items from a given sequence of text or speech. The item can be phonemes, syllables, letters, or words depending on the application, but when most people talk about n-grams, they mean a group of \\(n\\) words (Hvitfeldt and Silge 2022).\n\n\n\n\n\nHvitfeldt, E., and J. Silge. 2022. Supervised Machine Learning for Text Analysis in R. CRC Press. https://smltar.com/.\n\n\nSilge, J., and D. Robinson. 2017. Text Mining with R: A Tidy Approach. O’Reilly Media. https://www.tidytextmining.com/."
  },
  {
    "objectID": "words.html#words-as-tokens",
    "href": "words.html#words-as-tokens",
    "title": "2  Extracting and Analyzing Words",
    "section": "2.1 Words as Tokens",
    "text": "2.1 Words as Tokens\nIn order to analyze natural language, the raw text needs to be somehow transformed into a numeric format. One way to do this is to split passages of text into elements of one or more words. This transformation of text into smaller units is called tokenization.\nLet’s test turning a few made-up movie review sentences into separate words.\n\nlibrary(tibble)\nlibrary(tidytext)\nlibrary(magrittr)\n\n# A few example sentences\nmovie_comments <- tibble(id = 1:6,\n       text = c(\"The movie was great.\",\n                \"The movie was bad.\",\n                \"I didn't care for the movie.\",\n                \"The movie was not bad at all.\",\n                \"The beginning of the movie was lousy, but it turned out the be one of the best I've ever seen.\",\n                \"The movie was quite alright.\"))\n\n# Split sentences into separate words\nmovie_comments %>% unnest_tokens(word, text)\n\n# A tibble: 46 × 2\n      id word  \n   <int> <chr> \n 1     1 the   \n 2     1 movie \n 3     1 was   \n 4     1 great \n 5     2 the   \n 6     2 movie \n 7     2 was   \n 8     2 bad   \n 9     3 i     \n10     3 didn't\n# … with 36 more rows\n\n\nThe unnest_tokens() function also strips all the punctuation, white spaces etc., and turns all the words into lowercase.\n\n2.1.1 TF-IDF\nTerm frequency (TF), inverse document frequency (IDF), and their product (TF-IDF) which describes the frequency of the term adjusted for how rarely it is used (Silge and Robinson 2017), are all quantities which can be used for assessing the importance of a word in a passage of text.\n\nThe statistic tf-idf is intended to measure how important a word is to a document in a collection (or corpus) of documents, for example, to one novel in a collection of novels or to one website in a collection of websites.\n\n\\[\nIDF(\\text{term}) = \\ln \\left( \\frac{n_{\\text{documents}}}{n_{documents containing term}} \\right)\n\\]\n\n\n\n\nSilge, J., and D. Robinson. 2017. Text Mining with R: A Tidy Approach. O’Reilly Media. https://www.tidytextmining.com/."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "Summary here…"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Hvitfeldt, E., and J. Silge. 2022. Supervised Machine Learning for\nText Analysis in R. CRC Press. https://smltar.com/.\n\n\nSilge, J., and D. Robinson. 2017. Text Mining with R: A\nTidy Approach. O’Reilly Media. https://www.tidytextmining.com/."
  }
]